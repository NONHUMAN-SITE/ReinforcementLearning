defaults:
  - env: cartpole
  - algorithm: ppo
  - _self_

train:
  total_timesteps: 100000
  seed: 42
  learning_rate: 0.001
  gamma: 0.99
  epsilon: 1.0
  update_frequency: 1000
  target_update_frequency: 1000

buffer:
  type: "basic"
  buffer_size: 10000
  batch_size: 64